{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## written by : Yoel Ross\n",
    "## email: yoel.ross@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## useful numpy functions:\n",
    " * where\n",
    " * take\n",
    " * argmin\n",
    " * logical_*\n",
    " * transpose\n",
    " * vstack, hstack, dstack\n",
    " * np.newaxis\n",
    " \n",
    "## working examples:\n",
    " * mapping mapping pixel values, three possible implementations\n",
    " * iou calculation, three possible methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from ipywidgets import interact, IntSlider\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions to know"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return all indices of values that match a value\n",
    "x = np.eye(3)\n",
    "np.where(x == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a new array from an existing one using indices\n",
    "x = np.eye(5)\n",
    "np.take(x, [0, 1], axis=0) # take rows\n",
    "np.take(x, [0, 1], axis=1) # take columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the index of the minimum value\n",
    "x = np.linspace(0, np.pi)\n",
    "print(x[np.argmin(x)], x[np.argmax(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can be applied across an axis as well!\n",
    "x = np.eye(5)\n",
    "print(np.argmax(x, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List vs. Vector operations\n",
    "Applying a linear function y = ax + b to a one dimensional array or list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_size = 100000\n",
    "py_list = [i for i in range(list_size)]\n",
    "np_vect = np.array(py_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_linear_func_py(py_list, a, b):\n",
    "    return [a*i+b for i in py_list]\n",
    "\n",
    "def apply_linear_func_np(vec, a ,b):\n",
    "    return a*vec + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.8 ms ± 6.14 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit apply_linear_func_py(py_list, 4, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206 µs ± 24.4 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit apply_linear_func_np(np_vect, 4, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this varry as the list gets larger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:05<00:00,  9.03it/s]\n"
     ]
    }
   ],
   "source": [
    "python_list_time = []\n",
    "numpy_vect_time = []\n",
    "convrsion_time = []\n",
    "for size in tqdm(range(100, 100000, 1000)):\n",
    "    # create the list and vector\n",
    "    py_list = [i for i in range(size)]\n",
    "    np_vect = np.array(py_list)\n",
    "    \n",
    "    # apply function to python list\n",
    "    t0 = time.time()\n",
    "    apply_linear_func_py(py_list, 4, 6)\n",
    "    t1 = time.time()\n",
    "    python_list_time.append(t1-t0)\n",
    "    \n",
    "    # apply function to numpy vector\n",
    "    t0 = time.time()\n",
    "    apply_linear_func_np(np_vect, 4, 6)\n",
    "    t1 = time.time()\n",
    "    numpy_vect_time.append(t1-t0)\n",
    "    \n",
    "    # time conversion from list to ndarray\n",
    "    t0 = time.time()\n",
    "    temp_array = np.array(py_list)\n",
    "    t1 = time.time()\n",
    "    convrsion_time.append(t1-t0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'time, ms')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(python_list_time, c='b', label=\"python list\")\n",
    "plt.plot(numpy_vect_time, c='r', label=\"numpy array\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"list/vector size\")\n",
    "plt.ylabel(\"time, ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about elementwise binary operations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup some lists\n",
    "l1 = list(range(1000))\n",
    "l2 = list(range(1000))\n",
    "%timeit [a+b for (a,b) in zip(l1, l2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.array(l1)\n",
    "a2 = np.array(l2)\n",
    "%timeit a1+a2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting lists to arrays\n",
    "Converting python data structures to numpy is rather costly. Converting back and forth should be avoided. If you are doing some heavy lifting, try and use numpy arrays only.\n",
    "\n",
    "Look at the running time of converting a list to an ndarray relative to applying a linear function to the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(2)\n",
    "plt.plot(python_list_time, c='b', label=\"python list linear op\")\n",
    "plt.plot(convrsion_time, c='r', label=\"constructing ndarray from list\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"list size\")\n",
    "plt.ylabel(\"time, ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you can't, and you are carrying out a number of seperate operations on the list, it might be worth it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(3)\n",
    "plt.plot(convrsion_time, c='k', label=\"conversion time\")\n",
    "for i in range(1,5):\n",
    "    plt.plot([i*t for t in python_list_time], label=f\"num ops: {i}\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lets take a look at reductions and order statistics \n",
    "assuming a 2D matrix, or a list of list, how fast can we reduce across rows? Across columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_sum_np = []\n",
    "row_sum_py = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size in tqdm(range(10, 10000, 1000)):\n",
    "    rand_mat = [[np.random.randint(0, 256) for v in range(size)] for v2 in range(size)]\n",
    "    rand_arr = np.array(rand_mat)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    sum_list = [sum(l) for l in rand_mat]\n",
    "    row_sum_py.append(time.time()-t0)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    sum_arr = np.sum(rand_arr, axis=0)\n",
    "    row_sum_np.append(time.time()-t0)\n",
    "\n",
    "plt.figure(4)\n",
    "plt.plot(row_sum_py, c='r', label=\"python time\")\n",
    "plt.plot(row_sum_np, c='b', label=\"numpy time\")\n",
    "plt.xlabel(\"matrix dim\")\n",
    "plt.ylabel(\"run time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting, or how to move your loops into C  \n",
    "Using for loops in python can often be avoided by using vectorized operations, and by a process called broadcasting.\n",
    "The term broadcasting describes how numpy treats arrays with different shapes during arithmetic operations. Subject to certain constraints, the smaller array is “broadcast” across the larger array so that they have compatible shapes. Broadcasting provides a means of vectorizing array operations so that looping occurs in C instead of Python. It does this without making needless copies of data and usually leads to efficient algorithm implementations. There are, however, cases where broadcasting is a bad idea because it leads to inefficient use of memory that slows computation.\n",
    "\n",
    "The most simple case of broadcasting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3])\n",
    "b = np.array([4])\n",
    "c = a + b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the scalar b is \"broadcasted\" to match the dimensions of a. Logically, think of b being copied along its only dimension to match the size of a.\n",
    "\n",
    "This same behavior can be applied to arrays with multiple dimension, and the essential behavior remains the same. Numpy logically duplicated the array along the mismatched dimension.\n",
    "\n",
    "When operating on two arrays, NumPy compares their shapes element-wise. It starts with the trailing dimensions, and works its way forward. Two dimensions are compatible when:\n",
    "   1. The dimensions are equal\n",
    "   2. one of the matching directions equal one.\n",
    "\n",
    "The array with the dimension that equlas 1 is broadcasted to match the second. Let's take a look at the first example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"shape of a: {a.shape}, shape of b: {b.shape}, shape of c after broadcasting -> {c.shape}\")      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an extensive explaination of the broadcasting mechanic, see the [numpy broadcasting manual](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study: mapping image pixels. \n",
    "let's consider a case where we want to implement a mapping of our image pixels to a small set of pixel values. We can choose which pixel to map to using the euclidian distance between the original pixel and the set of target pixels, choosing the target with the minimum distance.\n",
    "\n",
    "#### The setup:\n",
    "   * We have a list of 256 triplets, each repersenting a pixel color we can map to.\n",
    "   * We have an input image with shape (200, 200, 3), we want to map each image pixel to the closest color given in the list.\n",
    "\n",
    "Example is based on the native python implementation found at [this repo.](https://github.com/magarcia/python-x256/blob/master/x256/x256.py)\n",
    "\n",
    "*source: Lisa Alali*\n",
    "#### First Attempt: Native Python\n",
    "The natural python implementation would use:    \n",
    "   1. list of colors\n",
    "   2. distance function: calculate distance between two pixels  \n",
    "   3. get mapped pixel: calculates distances between a pixel and all other 256 colors, returns the minimum  \n",
    "   4. map image: iterates through each image pixel and maps it, returning a mapped image.  \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "def __distance(a, b):\n",
    "    \"\"\"\n",
    "    euclidian distance between to 3-tuples.\n",
    "    \"\"\"\n",
    "    x = (a[0] - b[0]) ** 2\n",
    "    y = (a[1] - b[1]) ** 2\n",
    "    z = (a[2] - b[2]) ** 2\n",
    "    return sqrt(x + y + z)\n",
    "\n",
    "\n",
    "def from_rgb(r, g=None, b=None):\n",
    "    \"\"\"\n",
    "    Return the nearest xterm 256 color code from rgb input.\n",
    "    \"\"\"\n",
    "    c = r if isinstance(r, list) else [r, g, b]\n",
    "    best = {}\n",
    "\n",
    "    for index, item in enumerate(colors):\n",
    "        d = __distance(item, c)\n",
    "        if(not best or d <= best['distance']):\n",
    "            best = {'distance': d, 'index': index}\n",
    "\n",
    "    if 'index' in best:\n",
    "        return best['index']\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def map_image_pixels(image):\n",
    "    \"\"\"\n",
    "    replace all image pixels with the closest xterm color\n",
    "    :param image: ndarray image\n",
    "    :return: ndarray image\n",
    "    \"\"\"\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            new_color = from_rgb(list(image[i, j]))\n",
    "            image[i, j] = np.array(colors[new_color])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The promised list of colors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __hex2rgb(hexa):\n",
    "    r = int(hexa[0:2], 16)\n",
    "    g = int(hexa[2:4], 16)\n",
    "    b = int(hexa[4:6], 16)\n",
    "    return [r, g, b]\n",
    "\n",
    "colors = list(map(__hex2rgb, [\"000000\", \"800000\",\"008000\" ,\"808000\" ,\"000080\" , \"800080\", \"008080\", \"c0c0c0\", \"808080\", \"ff0000\", \"00ff00\", \"ffff00\", \"0000ff\", \"ff00ff\",  \n",
    "                              \"005f00\", \"005f5f\", \"005f87\", \"005faf\", \"005fd7\", \"005fff\", \"008700\", \"00875f\", \"008787\", \"0087af\", \"0087d7\", \"ffffff\", \"000000\", \"00005f\", \n",
    "                              \"0087ff\", \"00af00\", \"00af5f\", \"00af87\", \"00afaf\", \"00afd7\", \"00afff\", \"00d700\", \"00d75f\", \"00d787\", \"00d7af\", \"000087\", \"0000af\", \"0000d7\", \n",
    "                              \"00d7d7\", \"00d7ff\", \"00ff00\", \"00ff5f\", \"00ff87\",  \"00ffaf\",\"00ffd7\", \"00ffff\", \"5f0000\", \"5f005f\", \"5f0087\", \"5f00af\", \"5f00d7\", \"5f00ff\",\n",
    "                              \"5f5f00\", \"5f5f5f\", \"5f5f87\", \"5f5faf\", \"5f5fd7\", \"5f5fff\", \"5f8700\", \"5f875f\", \"5f8787\", \"5f87af\", \"5f87d7\", \"0000ff\", \"00ffff\",\n",
    "                              \"5f87ff\", \"5faf00\", \"5faf5f\", \"5faf87\", \"5fafaf\", \"5fafd7\", \"5fafff\", \"5fd700\", \"5fd75f\", \"5fd787\", \"5fd7af\",\n",
    "                              \"5fd7d7\", \"5fd7ff\", \"5fff00\", \"5fff5f\", \"5fff87\", \"5fffaf\", \"5fffd7\", \"5fffff\", \"870000\", \"87005f\", \"870087\",\n",
    "                              \"8700af\", \"8700d7\", \"8700ff\", \"875f00\", \"875f5f\", \"875f87\", \"875faf\", \"875fd7\", \"875fff\", \"878700\", \"87875f\",\n",
    "                              \"878787\", \"8787af\", \"8787d7\", \"8787ff\", \"87af00\", \"87af5f\", \"87af87\", \"87afaf\", \"87afd7\", \"87afff\", \"87d700\",\n",
    "                              \"87d75f\", \"87d787\", \"87d7af\", \"87d7d7\", \"87d7ff\", \"87ff00\", \"87ff5f\", \"87ff87\", \"87ffaf\", \"87ffd7\", \"87ffff\",\n",
    "                              \"af0000\", \"af005f\", \"af0087\", \"af00af\", \"af00d7\", \"af00ff\", \"af5f00\", \"af5f5f\", \"af5f87\", \"af5faf\", \"af5fd7\",\n",
    "                              \"af5fff\", \"af8700\", \"af875f\", \"af8787\", \"af87af\", \"af87d7\", \"af87ff\", \"afaf00\", \"afaf5f\", \"afaf87\", \"afafaf\",\n",
    "                              \"afafd7\", \"afafff\", \"afd700\", \"afd75f\", \"afd787\", \"afd7af\", \"afd7d7\", \"afd7ff\", \"afff00\", \"afff5f\", \"afff87\",\n",
    "                              \"afffaf\", \"afffd7\", \"afffff\", \"d70000\", \"d7005f\", \"d70087\", \"d700af\", \"d700d7\", \"d700ff\", \"d75f00\", \"d75f5f\", \"d75f87\", \"d75faf\", \"d75fd7\",\n",
    "                              \"d75fff\", \"d78700\", \"d7875f\", \"d78787\", \"d787af\", \"d787d7\", \"d787ff\", \"d7af00\", \"d7af5f\", \"d7af87\", \"d7afaf\", \"d7afd7\", \"d7afff\", \"d7d700\",\n",
    "                              \"d7d75f\", \"d7d787\", \"d7d7af\", \"d7d7d7\", \"d7d7ff\", \"d7ff00\", \"d7ff5f\", \"d7ff87\", \"d7ffaf\", \"d7ffd7\", \"d7ffff\", \"ff0000\", \"ff005f\", \"ff0087\",\n",
    "                              \"ff00af\", \"ff00d7\", \"ff00ff\", \"ff5f00\", \"ff5f5f\", \"ff5f87\", \"ff5faf\", \"ff5fd7\", \"ff5fff\", \"ff8700\", \"ff875f\", \"ff8787\", \"ff87af\", \"ff87d7\",\n",
    "                              \"ff87ff\", \"ffaf00\", \"ffaf5f\", \"ffaf87\", \"ffafaf\", \"ffafd7\", \"ffafff\", \"ffd700\", \"ffd75f\", \"ffd787\", \"ffd7af\", \"ffd7d7\", \"ffd7ff\", \"ffff00\",\n",
    "                              \"ffff5f\", \"ffff87\", \"ffffaf\", \"ffffd7\", \"ffffff\", \"080808\", \"121212\", \"1c1c1c\", \"262626\", \"303030\", \"3a3a3a\", \"444444\", \"4e4e4e\", \"585858\",\n",
    "                              \"606060\", \"666666\", \"767676\", \"808080\", \"8a8a8a\", \"949494\", \"9e9e9e\", \"a8a8a8\", \"b2b2b2\", \"bcbcbc\", \"c6c6c6\", \"d0d0d0\", \"dadada\", \"e4e4e4\",\n",
    "                              \"eeeeee\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How fast does this run?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.random.randint(0, 256, 200*200*3).reshape((200, 200, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit map_image_pixels(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is unfortunate, esspecially considering the small size of the image.  \n",
    "If we wanted to carry this operation out on our whole dataset, we would have a problem.\n",
    "\n",
    "#### Second Attempt: Vectorizing distance calculation\n",
    "The distance calculation is simple arithmatic, we can use broadcasting to calculate the distance from a pixel to  \n",
    "all the others in one shot. For this, we need to convert our color list into a matrix we can use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color matrix\n",
    "color_matrix = np.vstack([np.array(c) for c in colors])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we adapt the distance calculation function, and the image mapping function to use the vectorized calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_rgb_vec(rgb: list):\n",
    "    \"\"\"\n",
    "    Return the nearest xterm 256 color code from rgb input.\n",
    "    \"\"\"\n",
    "    # convert to ndarray\n",
    "    c = np.array(rgb)\n",
    "\n",
    "    # calculate the ditances to each color in color mat\n",
    "    all_distances = np.sum(np.sqrt((color_matrix-c)**2), axis=1)\n",
    "\n",
    "    # get the minimum color index\n",
    "    min_color = np.argmin(all_distances)\n",
    "    return min_color\n",
    "\n",
    "def map_image_pixels_vec(image):\n",
    "    \"\"\"\n",
    "    replace all image pixels with the closest xterm color,\n",
    "    calculates distances with vector arithmatic.\n",
    "    :param image: ndarray image\n",
    "    :return: ndarray image\n",
    "    \"\"\"\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            new_color = from_rgb_vec(image[i, j])\n",
    "            image[i, j] = np.array(colors[new_color])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How fast does this run?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit map_image_pixels_vec(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad! 20 fold speedup almost for free. All we did was create a ndarray out of the colors list (pay once per import), and use some simple vector operations. Can we do better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third Attempt: Calculate for all pixels at one  \n",
    "Using the same kind of broadcasting we used for each pixel, we can carry out all the distance computation in one shot. This is where broadcasting really becomes interesting. It might be a little hard to grasp at first, so lets do this step by step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_image_pixels_broad(image):\n",
    "    \"\"\"\n",
    "    replaces all image pixels with closest xterm colors,\n",
    "    calculates the distances and constructs the new image\n",
    "    using vector math and broadcasting.\n",
    "    :param image: ndarray\n",
    "    :return: ndarray\n",
    "    \"\"\"\n",
    "    # reshape image for ease of broadcasting\n",
    "    pixel_column = image.reshape(1, image.shape[0]*image.shape[1], 3)\n",
    "\n",
    "    # move axis for color matrix\n",
    "    broad_color_mat = color_matrix.reshape(color_matrix.shape[0], 1, 3)\n",
    "\n",
    "    # distance matrix, broadcasting happens here!\n",
    "    distance_matrix = np.sum(np.sqrt((broad_color_mat-pixel_column)**2), axis=2)\n",
    "\n",
    "    # min dist colors\n",
    "    min_dist_indices = np.argmin(distance_matrix, axis=0)\n",
    "\n",
    "    # take the pixels from the color mat\n",
    "    new_pixel_column = np.take(color_matrix, min_dist_indices, axis=0)\n",
    "\n",
    "    # reshape back to original shape\n",
    "    new_image = new_pixel_column.reshape((image.shape[0], image.shape[1], 3))\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first, lets remove one of the dimensions of the image by turning it into a pixel column. This makes working on it easier, and we can put it back together later. the image shape will be changed from (200, 200, 3) to (200*200, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_column = image.reshape(image.shape[0]*image.shape[1], 3)\n",
    "pixel_column.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seeing as we want to compute the distance from each image pixel, to each color pixel, we can use the broadcasting rules by adding a dimension of 1 to this pixel column. When we calculate the distance from the colors, the pixel column will be broadcasted along this dimension, and we will get what we are looking for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_column = pixel_column[np.newaxis, :, :]\n",
    "pixel_column.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets sort out the colors matrix, we need to add a dimension here as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move axis for color matrix\n",
    "broad_color_mat = color_matrix[:, np.newaxis, :]\n",
    "broad_color_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we subtract these arrays, the broadcasting will cause the given arrays to be \"coppied\" along the dimensions that match ones. This well given us a subtraction of each image pixel from all color pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_matrix = broad_color_mat-pixel_column\n",
    "sub_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "success! Now we need to raise by the power of 2 and take a square root. Numpy has vectorized functions for this as well. After that, all we need for the distances is to sum across the differences for each of the rgb values, which in our case, is repersented by the 3rd dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "almost_distance = np.sqrt(sub_matrix**2)\n",
    "almost_distance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix = np.sum(almost_distance, axis=2)\n",
    "distance_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want the index of the minimum distance for each image pixel. In matrix-speak, this means taking the minimum index from each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dist_indices = np.argmin(distance_matrix, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost last step, we want to rebuild or image pixel column, taking the corrisponding color pixels from the color matrix. Numpy has a built in function for this as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pixel_column = np.take(color_matrix, min_dist_indices, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lastly, we reshape the new pixel column to our original image dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image_broad = new_pixel_column.reshape((image.shape[0], image.shape[1], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how much have we gained by using broadcasting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit map_image_pixels_broad(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like we get another 20% increase relative to the simple vectorized version!\n",
    "\n",
    "Lets make sure the results are equivalent throughout the three attempts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_map = map_image_pixels(image)\n",
    "vectorized_map = map_image_pixels_vec(image)\n",
    "broadcast_map = map_image_pixels_broad(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"regular=vectorized: {np.array_equal(regular_map, vectorized_map)}, vectorized=broadcast: {np.array_equal(vectorized_map, broadcast_map)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study: Intersection Over Union calculations\n",
    "\n",
    "When carrying out segmentation or detection tasks, we find ourselves measuring the preformance of our models using the IOU matric. When carried out sequentially, this can be a slow task. Using numpy, we can vectorize many of these operations and reduce running time considerably.\n",
    "\n",
    "Lets load some data, i'm using the Penn pedastrian dataset, it provides images and masks of pedestrains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets load a sample image\n",
    "image_dir = \"PennFudanPed/PNGImages\"\n",
    "masks_dir = \"PennFudanPed/PedMasks\"\n",
    "image_paths = [os.path.join(image_dir, f) for f in os.listdir(image_dir)]\n",
    "\n",
    "@interact(image_id=IntSlider(min=0, max=len(image_paths)-1, step=1, value=0))\n",
    "def show_image(image_id=0):\n",
    "    plt.close()\n",
    "    ped_img = cv2.cvtColor(cv2.imread(image_paths[image_id]), cv2.COLOR_BGR2RGB)\n",
    "    mask_path = image_paths[image_id].split(\"/\")[-1].split(\".\")[0] + \"_mask.png\"\n",
    "    ped_msk = cv2.imread(os.path.join(masks_dir, mask_path))\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    ax[0].imshow(ped_img)\n",
    "    ax[1].matshow(np.sum(ped_msk, axis=2))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets grab a random sample, need to convert to RGB, cv2 default is BGR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = 32\n",
    "ped_img = cv2.cvtColor(cv2.imread(image_paths[image_id]), cv2.COLOR_BGR2RGB)\n",
    "mask_path = image_paths[image_id].split(\"/\")[-1].split(\".\")[0] + \"_mask.png\"\n",
    "ped_msk = cv2.imread(os.path.join(masks_dir, mask_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converting the masks into a tensor of binary masks instead of unique pixel value should make things easier. Just for practice, can we do this using a loop? or broadcasting?\n",
    "\n",
    "#### first try, regular loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loop implementation, slightly slower and more verbose\n",
    "def split_mask_for(mask):\n",
    "    unq = np.unique(mask)\n",
    "    mask_mat = np.array(mask[:, :, 0])\n",
    "    masks = []\n",
    "    for c in unq:\n",
    "        masks.append((mask_mat == c))\n",
    "    return np.dstack(masks).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit split_mask_for(ped_msk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### second try, lets use broadcasting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# broadcasting trick to split image to mask tensor\n",
    "def split_mask(mask):\n",
    "    # unique values in the image + reshape\n",
    "    uniq = np.unique(mask)\n",
    "    uniq = uniq[np.newaxis, np.newaxis, :]\n",
    "    # create 2d mask + reshape\n",
    "    mask_mat = np.array(mask[:, :, 0])[:, :, np.newaxis]\n",
    "    # compare and create binary mask\n",
    "    return (mask_mat == uniq).astype(np.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit split_mask(ped_msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = split_mask(ped_msk)\n",
    "m = split_mask(ped_msk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Native python implementation: Loops only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def native_iou(pred, masks):\n",
    "    num_preds = pred.shape[2]\n",
    "    num_masks = masks.shape[2]\n",
    "    iou_mat = np.zeros((num_masks, num_preds))\n",
    "    for pid in range(num_preds):\n",
    "        for mid in range(num_masks):\n",
    "            inter = 0\n",
    "            union = 0\n",
    "            for row in range(pred.shape[0]):\n",
    "                for col in range(pred.shape[1]):\n",
    "                    inter += int(pred[row, col, pid] and masks[row, col, mid])\n",
    "                    union += int(pred[row, col, pid] or masks[row, col, mid])\n",
    "            iou_mat[mid, pid] = 0 if (union == 0) else (inter / union)\n",
    "    return iou_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit native_iou(p, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Attempt: Nested Loops, simple array operations  \n",
    "keep it simple and pythonic, nested loops, calculate intersection and union for each pair and build a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_iou(pred, masks):\n",
    "    # create intersection and union matrices\n",
    "    intersection = np.zeros((pred.shape[2], masks.shape[2]))\n",
    "    union = np.zeros_like(intersection)\n",
    "    \n",
    "    for i in range(pred.shape[2]):\n",
    "        for j in range(masks.shape[2]):\n",
    "            intersection[i,j] = np.logical_and(pred[:,:, i], masks[:, :, j]).sum()\n",
    "            union[i, j] = np.logical_or(pred[:,:, i], masks[:, :, j]).sum()\n",
    "    return intersection/union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit loop_iou(p, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Attempt: save a loop by broadcasting each pred to all masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_iou2(pred, masks):\n",
    "    # create intersection and union matrices\n",
    "    intersection = np.zeros((pred.shape[2], masks.shape[2]))\n",
    "    union = np.zeros_like(intersection)    \n",
    "    iou_vecs = []\n",
    "    for i in range(pred.shape[2]):\n",
    "        temp_pred = np.array(pred[:, :, i])[:, :, np.newaxis]  # this looks like its going to slow things down\n",
    "        intersection = np.logical_and(temp_pred, masks).sum(axis=(0,1))\n",
    "        union = np.logical_or(temp_pred, masks).sum(axis=(0,1))\n",
    "        iou_vecs.append(intersection/union)\n",
    "    return np.vstack(iou_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit loop_iou2(p, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third Attempt: no loops at all, use only broadcasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_iou(pred, masks):\n",
    "    print(f\"masks: {masks.shape}\")\n",
    "    print(f\"pred: {pred.shape}\")\n",
    "    pred = pred[np.newaxis, :]\n",
    "    masks = np.transpose(masks[np.newaxis, :], (3,1,2,0))\n",
    "    print(f\"masks: {masks.shape}\")\n",
    "    print(f\"pred: {pred.shape}\")\n",
    "    intersection = np.sum(np.logical_and(pred, masks), axis=(1, 2))\n",
    "    union = np.sum(np.logical_or(pred, masks), axis=(1, 2))\n",
    "    print(f\"final: {intersection.shape}\")\n",
    "    return intersection/union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
